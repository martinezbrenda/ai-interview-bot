# ğŸ¤– AI Interview Bot

Sistema integral de preparaciÃ³n para entrevistas tÃ©cnicas de **AI Engineer**. Este proyecto utiliza una arquitectura de microservicios para ofrecer una experiencia bimodal: **preparaciÃ³n tÃ©cnica** y **gestiÃ³n psicotÃ©cnica (soft skills)**.

## ğŸ¯ Objetivo del Proyecto

El propÃ³sito de este sistema es demostrar la capacidad de **integraciÃ³n end-to-end** de un ecosistema moderno de IA, resolviendo retos comunes en el desarrollo de agentes inteligentes:

* **Desarrollo Backend:** ImplementaciÃ³n de una **API RESTful** robusta utilizando **Node.js** y **Express**.
* **Contextual AI Anchor:** Capacidad de analizar **Job Descriptions** externos para personalizar el entrenamiento.
* **Prompt Engineering Avanzado:** DiseÃ±o de un agente con lÃ³gica bimodal y adaptabilidad de contexto mediante el SDK de **Groq** (Llama 3.3 70B).
* **SincronizaciÃ³n de Sistemas:** RecepciÃ³n, validaciÃ³n y procesamiento de **Webhooks** en tiempo real.
* **OrquestaciÃ³n No-Code:** AutomatizaciÃ³n de flujos de trabajo complejos y conexiÃ³n de servicios externos con **n8n**.
* **Resiliencia:** Manejo de errores y degradaciÃ³n elegante del servicio ante fallos de infraestructura.
* **Ciclo de Vida de Software (SDLC):** GestiÃ³n de versiones con **Git/GitHub** y despliegue continuo (CI/CD) en la nube mediante **Railway**.

## ğŸ—ï¸ Arquitectura y Flujo de EjecuciÃ³n

El sistema opera bajo un modelo de microservicios desacoplados para garantizar escalabilidad y facilidad de mantenimiento:

**Diagrama de Flujo:**
`Usuario (Telegram) â†’ n8n Orquestador (Webhook) â†’ Backend (Express API) â†’ IA (Groq LLM) â†’ Respuesta Estructurada (JSON)`

### Pipeline de ejecuciÃ³n:

1. **Ingesta**: El usuario envÃ­a texto o un archivo `.txt` vÃ­a Telegram.
2. **ETL en el Edge (n8n)**: El orquestador extrae el contenido binario y lo transforma en un string estructurado.
3. **InyecciÃ³n de Contexto**: El backend en **Railway** recibe el mensaje y la **Job Description**, anclÃ¡ndolos como prioridad en la memoria de la sesiÃ³n.
4. **Inferencia de IA**: Se consulta al modelo **Llama 3.3 70B** vÃ­a **Groq SDK** aplicando un **System Prompt** bimodal.
5. **Entrega Multiformato**: El nodo **Code** en n8n detecta el cliente (Telegram o Terminal) y aplica formato HTML o secuencias **ANSI** respectivamente.

## ğŸ§  GestiÃ³n de Memoria y Estados (Stateful AI)

A diferencia de implementaciones *stateless*, este bot mantiene la coherencia mediante:

* **Session Management**: GestiÃ³n de objetos de sesiÃ³n indexados por `userId` en memoria volÃ¡til.
* **Sliding Window Memory**: Ventana deslizante que preserva el **System Prompt** y la **Job Description**, eliminando turnos intermedios para optimizar la ventana de contexto (128k tokens).
* **Reset Logic**: Endpoint dedicado para la limpieza sÃ­ncrona de estados.

## ğŸš€ Funcionalidades Principales

### 1. PreparaciÃ³n Bimodal

* **Modo RelajaciÃ³n**: TÃ©cnicas de mindfulness y preparaciÃ³n psicolÃ³gica pre-entrevista.
* **Modo PrÃ¡ctica**: Simulacros tÃ©cnicos con detecciÃ³n de "humo" y validaciÃ³n de conceptos clave (Webhooks, GraphQL, LangChain).

### 2. AnÃ¡lisis DinÃ¡mico de JDs

El backend permite inyectar descriptivos de puesto para:

* Generar preguntas de validaciÃ³n crÃ­tica basadas en el stack real de la empresa.
* Identificar brechas de conocimiento especÃ­ficas para el candidato.


## ğŸ§  LÃ³gica del Agente (Prompt Engineering)

El bot opera bajo dos modos principales configurados mediante un **System Prompt** avanzado:

### 1. RelajaciÃ³n Pre-Entrevista

* **Entrevistado:** TÃ©cnicas de mindfulness, respiraciÃ³n y rutinas de confianza.
* **Entrevistador:** TÃ©cnicas de rapport y creaciÃ³n de ambientes profesionales.

### 2. PrÃ¡ctica TÃ©cnica

* **DetecciÃ³n de Humo:** Preguntas punzantes para validar experiencia real en niveles Junior, Mid y Senior.
* **Key Indicators:** DefiniciÃ³n de conceptos clave que el candidato debe mencionar para demostrar dominio.
* **MÃ©todo STAR:** GuÃ­a para estructurar respuestas comportamentales.

## ğŸš€ InstalaciÃ³n y Setup

### Requisitos

* **Node.js** >= 20.x
* **Groq API Key**
* **n8n instance** (Local o Cloud)

### ConfiguraciÃ³n .env

```env
GROQ_API_KEY=your_key_here
PORT=3000

```

## ğŸ› ï¸ Stack TecnolÃ³gico

| CategorÃ­a | TecnologÃ­a | Rationale |
| --- | --- | --- |
| **Runtime** | Node.js 22 | Estabilidad y soporte de APIs modernas. |
| **Framework** | Express.js | Ligereza para microservicios RESTful. |
| **AI Engine** | Groq (Llama 3.3 70B) | Inferencia ultra-rÃ¡pida (LPU Technology). |
| **OrquestaciÃ³n** | n8n | AutomatizaciÃ³n de flujos de trabajo sin cÃ³digo. |
| **Infraestructura** | Railway | Despliegue continuo (CI/CD) y PaaS seguro. |

## ğŸ§ª Endpoints Principales

* `POST /webhook/message`: Punto de entrada principal para n8n. Gestiona el procesamiento de mensajes mediante el SDK de Groq.
* POST /api/chat: Interfaz programÃ¡tica para inyecciÃ³n de JDs y mensajes.
* `GET /health`: Monitoreo del estado del servicio y latencia.

---

## ğŸ‘¤ Autor

**Brenda Martinez**  
AI Engineer & Data Scientist

- ğŸ“§ Email: brendacarolinamartinez888@gmail.com
- ğŸ’¼ LinkedIn: [/martinezbrendacarolina](https://linkedin.com/in/martinezbrendacarolina)
- ğŸ“ WhatsApp: +54 11 2297 3347

---

